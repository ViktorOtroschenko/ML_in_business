{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mineral-tyler",
   "metadata": {},
   "source": [
    "## Профилирование пользователей. Сегментация: unsupervised learning (clustering, LDA/ARTM), supervised (multi/binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-tiger",
   "metadata": {},
   "source": [
    "1. Самостоятельно разобраться с тем, что такое tfidf (документация https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html и еще - https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "2. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)\n",
    "3. Повторить п.2, но используя уже не медиану, а max\n",
    "4. (опциональное, если очень хочется) Воспользовавшись полученными знаниями из п.1, повторить пункт 2, но уже взвешивая новости по tfidf (подсказка: нужно получить веса-коэффициенты для каждого документа. Не все документы одинаково информативны и несут какой-то положительный сигнал). Подсказка 2 - нужен именно idf, как вес.\n",
    "5. Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score\n",
    "6. Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "danish-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import re\n",
    "import numpy as np\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chinese-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"articles.csv\")\n",
    "users = pd.read_csv(\"users_articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broken-lancaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(news.shape, news.head(3), users.shape, users.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instrumental-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ru = nltk.corpus.stopwords.words('russian')\n",
    "len(stopword_ru)\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unusual-superintendent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wanted-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Очистка текста\n",
    "    :return: Очищеный текст\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '',\n",
    "                  text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "\n",
    "    # tokens = list(tokenize(text))\n",
    "    # words = [_.text for _ in tokens]\n",
    "    # words = [w for w in words if w not in stopword_ru]\n",
    "\n",
    "    # return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "\n",
    "cache = {}\n",
    "\n",
    "\n",
    "def lemmatization(text):\n",
    "    \"\"\"\n",
    "    Лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "    :return: Список отлемматизированых токенов\n",
    "    \"\"\"\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-':  # [2]\n",
    "            w = w[1:]\n",
    "        if len(w) > 1:  # [3]\n",
    "            if w in cache:  # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else:  # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "\n",
    "    words_lem_without_stopwords = [\n",
    "        i for i in words_lem if not i in stopword_ru\n",
    "    ]  # [6]\n",
    "\n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efficient-enforcement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-5c199c8b6c00>:13: FutureWarning: Possible nested set at position 39\n",
      "  text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем очистку текста. Будет долго...\n",
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "copyrighted-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем лемматизацию текста. Будет очень долго...\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "athletic-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сформируем список наших текстов, разбив еще и на пробелы\n",
    "texts = [t for t in news['title'].values]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "knowing-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ватутин', 'взаимодействие', 'власть', 'войти', 'вячеслав']\n"
     ]
    }
   ],
   "source": [
    "print([common_dictionary[i] for i in range(10, 15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stunning-central",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=25, id2word=common_dictionary, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "known-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "# Save model to disk.\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "designing-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'свой', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атланта', 'nnnn', 'провести', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'работа', 'сказать', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'мочь', 'играть', 'ещё', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'это', 'хороший']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.022014042),\n",
       " (2, 0.26350155),\n",
       " (6, 0.045580126),\n",
       " (9, 0.17619471),\n",
       " (12, 0.023242133),\n",
       " (15, 0.12485316),\n",
       " (21, 0.32893026)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new corpus, made of previously unseen documents.\n",
    "# Создайте новый корпус, состоящий из ранее невидимых документов.\n",
    "other_texts = [t for t in news['title'].iloc[:3]]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "unseen_doc = other_corpus[2]\n",
    "\n",
    "print(other_texts[2])\n",
    "lda[unseen_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "brief-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: снижение казахстан грант финляндия дания гражданство финский\n",
      "topic_1: место энергия высота рейтинг физика отель гостиница\n",
      "topic_2: прогнозировать сон игра команда польский польша золото\n",
      "topic_3: территория страна который санкция китай российский взрыв\n",
      "topic_4: город человек произойти дом житель тело местный\n",
      "topic_5: экономика доход эксперимент рост фестиваль школа бизнес\n",
      "topic_6: газ фонд альянс тепло рт проект шоу\n",
      "topic_7: германия европа страна франция турецкий европейский турция\n",
      "topic_8: украина военный украинский армия операция сила киев\n",
      "topic_9: британский великобритания nthe лондон сообщать клуб употребление\n",
      "topic_10: сша это россия страна российский банк американский\n",
      "topic_11: год млрд рубль млн рынок цена тыс\n",
      "topic_12: ракета запуск северный продукция ниже блок солнце\n",
      "topic_13: который дело год смерть экипаж проверка расследование\n",
      "topic_14: суд дело год статья уголовный компания решение\n",
      "topic_15: это который nn глава правительство вопрос должный\n",
      "topic_16: nn москва год день сайт пройти стать\n",
      "topic_17: человек исследование ребёнок год который жизнь университет\n",
      "topic_18: земля выяснить станция температура вода век обнаружить\n",
      "topic_19: год который это время мочь компания новый\n",
      "topic_20: nn женщина человек погибнуть сотрудник nnn который\n",
      "topic_21: это мочь всё весь большой день журнал\n",
      "topic_22: россия российский путин nn владимир президент москва\n",
      "topic_23: сенатор выдавать парижский мотив филипп джим многократный\n",
      "topic_24: донбасс принадлежащий челябинский донецкий конкурентный минский вмф\n"
     ]
    }
   ],
   "source": [
    "x=lda.show_topics(num_topics=25, num_words=7,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "#Below Code Prints Only Words \n",
    "for topic,words in topics_words:\n",
    "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "median-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(\n",
    "        zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(25):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "terminal-registration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027484</td>\n",
       "      <td>0.039135</td>\n",
       "      <td>0.075073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368260</td>\n",
       "      <td>0.375868</td>\n",
       "      <td>0.104936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.022014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id   topic_0  topic_1   topic_2   topic_3   topic_4  topic_5   topic_6  \\\n",
       "0       6  0.000000      0.0  0.064307  0.000000  0.000000      0.0  0.011277   \n",
       "1    4896  0.000000      0.0  0.368260  0.375868  0.104936      0.0  0.000000   \n",
       "2    4897  0.022014      0.0  0.263512  0.000000  0.000000      0.0  0.045581   \n",
       "3    4898  0.000000      0.0  0.104255  0.000000  0.000000      0.0  0.000000   \n",
       "4    4899  0.000000      0.0  0.000000  0.000000  0.243905      0.0  0.000000   \n",
       "\n",
       "   topic_7  topic_8  ...  topic_15  topic_16  topic_17  topic_18  topic_19  \\\n",
       "0      0.0      0.0  ...  0.425073       0.0  0.027484  0.039135  0.075073   \n",
       "1      0.0      0.0  ...  0.061064       0.0  0.000000  0.000000  0.000000   \n",
       "2      0.0      0.0  ...  0.124779       0.0  0.000000  0.000000  0.000000   \n",
       "3      0.0      0.0  ...  0.386608       0.0  0.030693  0.000000  0.104314   \n",
       "4      0.0      0.0  ...  0.548410       0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "   topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0       0.0  0.000000  0.158988       0.0  0.000000  \n",
       "1       0.0  0.000000  0.000000       0.0  0.000000  \n",
       "2       0.0  0.329002  0.000000       0.0  0.000000  \n",
       "3       0.0  0.235001  0.000000       0.0  0.012387  \n",
       "4       0.0  0.000000  0.000000       0.0  0.000000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
    "topic_matrix.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-physiology",
   "metadata": {},
   "source": [
    "### Векторные представления пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "professional-consumer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "optical-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "martial-expression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01767998, 0.        , 0.        , 0.        , 0.05064018,\n",
       "       0.08978008, 0.        , 0.        , 0.07530002, 0.05188583,\n",
       "       0.        , 0.12413256, 0.10266267, 0.        , 0.03947233,\n",
       "       0.26328352, 0.09603399, 0.08061683, 0.        , 0.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict[293622]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "congressional-kenya",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[323329, 321961, 324743, 323186, 324632, 474690]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[323329, 321961, 324743, 323186, 324632, 474690]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_articles_list = users['articles'].iloc[33]\n",
    "display(user_articles_list, \n",
    "        eval(user_articles_list)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mechanical-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_mean(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.mean(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hidden-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_median(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.median(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "imperial-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding_max(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.max(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "banned-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_with_user_embedding(func):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix\n",
    "\n",
    "    user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: func(x), 1)])\n",
    "    user_embeddings.columns = [f'topic_{i}' for i in range(25)]\n",
    "    user_embeddings['uid'] = users['uid'].values\n",
    "    user_embeddings = user_embeddings[['uid'] + [f'topic_{i}' for i in range(25)]]\n",
    "\n",
    "    X = pd.merge(user_embeddings, target, 'left')\n",
    "\n",
    "    #разделим данные на train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X[[f'topic_{i}' for i in range(25)]], X['churn'], random_state=0)\n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    #обучим наш пайплайн\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    #наши прогнозы для тестовой выборки\n",
    "    preds = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Рассчитаем Precision, Recall, F_score, roc_auc_score\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    roc_auc_score = roc_auc_score(y_test, preds)\n",
    "\n",
    "    return round(thresholds[ix], 4), round(fscore[ix], 4), round(precision[ix], 4), round(recall[ix], 4), round(roc_auc_score, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "reverse-sender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u107120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u102277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u102444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  churn\n",
       "0  u107120      0\n",
       "1  u102277      0\n",
       "2  u102444      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(\"users_churn.csv\")\n",
    "target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "referenced-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "resul = score_with_user_embedding(func=get_user_embedding_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "played-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(np.array([\n",
    "    score_with_user_embedding(func=get_user_embedding_mean),\n",
    "    score_with_user_embedding(func=get_user_embedding_median),\n",
    "    score_with_user_embedding(func=get_user_embedding_max)\n",
    "]), columns=['Best Threshold', 'F-Score', 'Precision', 'Recall', 'ROC AUC score'])\n",
    "\n",
    "results['func'] = ['mean', 'median', 'max']\n",
    "results = results.set_index('func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "indoor-harvest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Threshold</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC AUC score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>func</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.7611</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>0.9661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.2816</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>0.9698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.3630</td>\n",
       "      <td>0.8208</td>\n",
       "      <td>0.8383</td>\n",
       "      <td>0.8041</td>\n",
       "      <td>0.9772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Best Threshold  F-Score  Precision  Recall  ROC AUC score\n",
       "func                                                             \n",
       "mean            0.2932   0.7611     0.7550  0.7673         0.9661\n",
       "median          0.2816   0.7751     0.7628  0.7878         0.9698\n",
       "max             0.3630   0.8208     0.8383  0.8041         0.9772"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-installation",
   "metadata": {},
   "source": [
    "Согласно результатам видно, что наилучший результат достигается через метод __max__.\n",
    "\n",
    "Скорее всего, разброс инетересов пользователей уменьшается, интересы становятся узко-направленными и точными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-samoa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
